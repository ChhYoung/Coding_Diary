{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逆向最大匹配法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_word(sentence, word_dic):\n",
    "    \"\"\"\n",
    "    sentence : 待切分的句子\n",
    "    word_dic : 字典\n",
    "    \"\"\"\n",
    "    # 找字典最大词长度\n",
    "    word_length_list = [len(word) for word in word_dic]\n",
    "    max_length = max(word_length_list)\n",
    "    # 句子长度\n",
    "    word_length = len(sentence)\n",
    "    # 存储分词结果\n",
    "    cut_word_list = []\n",
    "    # 判断句子的长度是否为0， 若为0， 则句子为空\n",
    "    while word_length > 0:\n",
    "        max_cut_length = min(max_length,word_length)\n",
    "        subsentence = sentence[-max_cut_length:]\n",
    "        while max_cut_length>0:\n",
    "            # 匹配\n",
    "            if subsentence in word_dic:\n",
    "                cut_word_list.append(subsentence)\n",
    "                break\n",
    "            # 单个字构成的词\n",
    "            elif max_cut_length == 1: \n",
    "                cut_word_list.append(subsentence)\n",
    "                break\n",
    "            else:\n",
    "                # 没有匹配\n",
    "                max_cut_length = max_cut_length - 1\n",
    "                subsentence = subsentence[-max_cut_length:]\n",
    "        # 剔除切分完的词\n",
    "        sentence = sentence[:-max_cut_length]\n",
    "        word_length = word_length - max_cut_length\n",
    "    return cut_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['逃跑', '方向', '海南', '沿']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '沿海南方向逃跑'\n",
    "word_dic = ['沿海','海南','南方','方向','逃跑']\n",
    "result = cut_word(sentence,word_dic)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维特比算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 维特比算法\n",
    "A = {'A1':2,'A2':4,'A3':1}\n",
    "\n",
    "B = {'B1':{'A1':6,'A2':7, 'A3':2},\n",
    "     'B2':{'A1':9,'A2':11,'A3':6},\n",
    "     'B3':{'A1':4,'A2':3 ,'A3':12}}\n",
    "\n",
    "C = {'C1':{'B1':3,'B2':6, 'B3':6},\n",
    "     'C2':{'B1':5,'B2':3, 'B3':1},\n",
    "     'C3':{'B1':2,'B2':7 ,'B3':2}}\n",
    "\n",
    "D = {'D1':{'C1':9,'C2':3, 'C3':7},\n",
    "     'D2':{'C1':3,'C2':5, 'C3':1},\n",
    "     'D3':{'C1':2,'C2':9 ,'C3':3}}\n",
    "\n",
    "E = {'E1':{'D1':1,'D2':2, 'D3':2},\n",
    "     'E2':{'D1':4,'D2':4, 'D3':8},\n",
    "     'E3':{'D1':7,'D2':1 ,'D3':3}}\n",
    "mat = [A,B,C,D,E]\n",
    "# 找最小路径\n",
    "def viterbi(mat):\n",
    "    tab = [{}] #存储【0，T-1】时间内每个时间状态的最优路径值 tab[t][state_i] = value\n",
    "    path = {}  #  存储对应节点所经过的最优路径\n",
    "    for state in mat[0].keys(): # 初始化选择A\n",
    "        tab[0][state] = mat[0][state]\n",
    "        path[state] = [state]\n",
    "    for t in range(1,len(mat)):\n",
    "        tab.append({})\n",
    "        new_path = {}\n",
    "        for state2 in mat[t].keys():\n",
    "            items = []\n",
    "            for state1 in mat[t-1].keys():\n",
    "                value = tab[t-1][state1] + mat[t][state2][state1]\n",
    "                items.append((value,state1))\n",
    "            # 取最小路径\n",
    "            min_value = min(items)\n",
    "            tab[t][state2] = min_value[0]\n",
    "            # 记录最优路径\n",
    "            new_path[state2] = path[min_value[1]] + [state2]\n",
    "        path = new_path\n",
    "    value,state = min( \n",
    "        [ (tab[len(mat)-1][state],state)  for state in mat[-1].keys() ]\n",
    "    )\n",
    "    \n",
    "    return path[state]\n",
    "\n",
    "# 同理HMM中求最大概率路径,得到隐含状态链\n",
    "# sentence[i]: 要分词的句子\n",
    "def predict(sentence,tran_prob_mat,emit_prob_mat,init_prob_mat):\n",
    "    tab = [{}]\n",
    "    path = {}\n",
    "    for state in states:\n",
    "        tab[0][state] = init_prob_mat.get(state)*\\\n",
    "                        emit_prob_mat[state].get(sentence[0],0.00001)\n",
    "        path[state] = [state]\n",
    "    for t in range(1,len(sentence)):\n",
    "        tab.append({})\n",
    "        new_path = {}\n",
    "        for state2 in states:\n",
    "            items = []\n",
    "            for state1 n states:\n",
    "                if tab[t-1][state1] == 0:\n",
    "                    continue\n",
    "                tran_prob = tran_prob_mat[state1].get(state1,0.00001)*\\\n",
    "                            emit_prob_mat[state2].get(sentence[i],0.00001)\n",
    "                prob = tab[t-1][state1]*tran_prob\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = viterbi(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A3', 'B1', 'C3', 'D2', 'E3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {'A1':2,'A2':4,'A3':1}\n",
    "\n",
    "B = {'B1':{'A1':6,'A2':7, 'A3':2},\n",
    "     'B2':{'A1':9,'A2':11,'A3':6},\n",
    "     'B3':{'A1':4,'A2':3 ,'A3':12}}\n",
    "\n",
    "C = {'C1':{'B1':3,'B2':6, 'B3':6},\n",
    "     'C2':{'B1':5,'B2':3, 'B3':1},\n",
    "     'C3':{'B1':2,'B2':7 ,'B3':2}}\n",
    "\n",
    "D = {'D1':{'C1':9,'C2':3, 'C3':7},\n",
    "     'D2':{'C1':3,'C2':5, 'C3':1},\n",
    "     'D3':{'C1':2,'C2':9 ,'C3':3}}\n",
    "\n",
    "E = {'E1':{'D1':1,'D2':2, 'D3':2},\n",
    "     'E2':{'D1':4,'D2':4, 'D3':8},\n",
    "     'E3':{'D1':7,'D2':1 ,'D3':3}}\n",
    "mat = [A,B,C,D,E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 2, 'A2': 4, 'A3': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A1', 'A2', 'A3'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
