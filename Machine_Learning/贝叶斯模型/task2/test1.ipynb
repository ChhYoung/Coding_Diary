{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.598 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#coding: utf-8\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import jieba\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import vstack\n",
    "\n",
    "def MakeWordsSet(words_file):\n",
    "    \"\"\"\n",
    "    函数说明:读取文件里的内容，并去重\n",
    "    Parameters:\n",
    "        words_file - 文件路径\n",
    "    Returns:\n",
    "        words_set - 读取的内容的set集合\n",
    "    \"\"\"\n",
    "    words_set = set()\n",
    "    with open(words_file, 'r') as fp:\n",
    "        for line in fp.readlines():\n",
    "            word = line.strip()#.decode(\"utf-8\")\n",
    "            if len(word)>0 and word not in words_set: # 去重\n",
    "                words_set.add(word)\n",
    "    return words_set\n",
    "\n",
    "def TextProcessing(folder_path, test_size=0.2):\n",
    "########################################### 使用 #######################################################\n",
    "# folder_path = './Database/SogouC/Sample'\n",
    "    \"\"\"\n",
    "    函数说明:中文文本处理\n",
    "    Parameters:\n",
    "        folder_path - 文本存放的路径\n",
    "        test_size - 测试集占比，默认占所有数据集的百分之20\n",
    "    Returns:\n",
    "        all_words_list - 按词频降序排序的训练集列表\n",
    "        train_data_list - 训练集列表\n",
    "        test_data_list - 测试集列表\n",
    "        train_class_list - 训练集标签列表\n",
    "        test_class_list - 测试集标签列表\n",
    "    \"\"\"\n",
    "    folder_list = os.listdir(folder_path)\n",
    "    data_list = []\n",
    "    class_list = []\n",
    "###################################################################################\n",
    "# data_list  ： 全部文本信息list\n",
    "# class_lsit ： 每个txt文件的类别标签\n",
    "    # 类间循环\n",
    "    for folder in folder_list:\n",
    "        new_folder_path = os.path.join(folder_path, folder)\n",
    "        files = os.listdir(new_folder_path)\n",
    "        # 类内循环\n",
    "        j = 1\n",
    "        for file in files:\n",
    "            if j > 100: # 每类text样本数最多100\n",
    "                break\n",
    "            with open(os.path.join(new_folder_path, file), 'r') as fp:\n",
    "               raw = fp.read()\n",
    "           \n",
    "            word_cut = jieba.cut(raw, cut_all=False) # 精确模式，返回的结构是一个可迭代的genertor\n",
    "            word_list = list(word_cut) # genertor转化为list，每个词unicode格式\n",
    "          \n",
    "            data_list.append(word_list)\n",
    "            class_list.append(folder)#.decode('utf-8')\n",
    "            j += 1\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    data_class_list = list(zip(data_list, class_list))\n",
    "    random.shuffle(data_class_list)\n",
    "    index = int(len(data_class_list)*test_size)#+1\n",
    "    train_list = data_class_list[index:]\n",
    "    test_list = data_class_list[:index]\n",
    "    train_data_list, train_class_list = zip(*train_list)\n",
    "    test_data_list, test_class_list = zip(*test_list)\n",
    "\n",
    "    # 统计词频放入all_words_dict\n",
    "    all_words_dict = {} \n",
    "    for word_list in train_data_list:\n",
    "        for word in word_list:\n",
    "            #if all_words_dict.has_key(word):\n",
    "            if word in all_words_dict.keys():\n",
    "                all_words_dict[word] += 1\n",
    "            else:\n",
    "                all_words_dict[word] = 1\n",
    "\n",
    "    # 根据键的值倒序排序\n",
    "    all_words_tuple_list = sorted(all_words_dict.items(), key=lambda f:f[1], reverse=True) # 内建函数sorted参数需为list\n",
    "    #all_words_list = list(zip(*all_words_tuple_list))[0]\n",
    "    all_words_list = list(zip(*all_words_tuple_list))[0]\n",
    "\n",
    "    return all_words_list, train_data_list, test_data_list, train_class_list, test_class_list\n",
    "\n",
    "def words_dict(all_words_list, deleteN, stopwords_set=set()):\n",
    "    \"\"\"\n",
    "    函数说明:文本特征选取\n",
    "    Parameters:\n",
    "        all_words_list - 训练集所有文本列表\n",
    "        deleteN - 删除词频最高的deleteN个词\n",
    "        stopwords_set - 指定的结束语\n",
    "    Returns:\n",
    "        feature_words - 特征集\n",
    "    \"\"\"\n",
    "    # 选取特征词\n",
    "    feature_words = []\n",
    "    n = 1\n",
    "    for t in range(deleteN, len(all_words_list), 1):\n",
    "        if n > 1000: # feature_words的维度1000\n",
    "            break\n",
    "        # 如果这个词不是数字，并且不是指定的结束语，并且单词长度大于1小于5，那么这个词就可以作为feature_word\n",
    "        if not all_words_list[t].isdigit() and all_words_list[t] not in stopwords_set and 1<len(all_words_list[t])<5:\n",
    "            feature_words.append(all_words_list[t])\n",
    "            n += 1\n",
    "    return feature_words\n",
    "\n",
    "def TextFeatures(train_data_list, test_data_list, feature_words):\n",
    "    \"\"\"\n",
    "    函数说明:根据feature_words将文本向量化\n",
    "    Parameters:\n",
    "        train_data_list - 训练集\n",
    "        test_data_list - 测试集\n",
    "        feature_words - 特征集\n",
    "    Returns:\n",
    "        train_feature_list - 训练集向量化列表\n",
    "        test_feature_list - 测试集向量化列表\n",
    "    \"\"\"\n",
    "    def text_features(text, feature_words):\n",
    "        text_words = set(text)\n",
    "        features = [1 if word in text_words else 0 for word in feature_words]\n",
    "        return features\n",
    "    train_feature_list = [text_features(text, feature_words) for text in train_data_list]\n",
    "    test_feature_list = [text_features(text, feature_words) for text in test_data_list]\n",
    "    return train_feature_list, test_feature_list\n",
    "\n",
    "def TextClassifier(train_feature_list, test_feature_list, train_class_list, test_class_list):\n",
    "    \"\"\"\n",
    "    函数说明:分类器\n",
    "    Parameters:\n",
    "        train_feature_list - 训练集向量化的特征文本\n",
    "        test_feature_list - 测试集向量化的特征文本\n",
    "        train_class_list - 训练集分类标签\n",
    "        test_class_list - 测试集分类标签\n",
    "    Returns:\n",
    "        test_accuracy - 分类器精度\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "        请编写这部分代码\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    return test_accuracy\n",
    "\n",
    "def Tuning():\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 文本预处理\n",
    "    folder_path = './Database/SogouC/Sample'\n",
    "    all_words_list, train_data_list, test_data_list, train_class_list, test_class_list = TextProcessing(folder_path, test_size=0.2)\n",
    "\n",
    "    # 生成stopwords_set\n",
    "    stopwords_file = './stopwords_cn.txt'\n",
    "    stopwords_set = MakeWordsSet(stopwords_file)\n",
    "\n",
    "    # 文本特征提取和分类\n",
    "    deleteN = 450\n",
    "    feature_words = words_dict(all_words_list, deleteN, stopwords_set)\n",
    "    train_feature_list, test_feature_list = TextFeatures(train_data_list, test_data_list, feature_words)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_list = list(train_feature_list)\n",
    "train_class_list = list(train_class_list)\n",
    "test_feature_list = list(test_feature_list)\n",
    "test_class_list = list(test_class_list)\n",
    "\n",
    "\n",
    "params = {'alpha':np.linspace(0.001,1,100)}\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangchonghuan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/yangchonghuan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_feature_list\n",
    "Y_train  = train_class_list\n",
    "\n",
    "X_val  = test_feature_list\n",
    "Y_val = test_class_list\n",
    "\n",
    "\n",
    "len_X_train = len(X_train)\n",
    "len_X_val = len(X_val)\n",
    "'''\n",
    "X_train.append(X_val)\n",
    "X = X_train\n",
    "Y_train.extend(Y_val)\n",
    "Y = Y_train'''\n",
    "X = vstack([X_train,X_val])\n",
    "X = np.array(X)\n",
    "Y_train.extend(Y_val)\n",
    "Y = np.array(Y_train)\n",
    "    \n",
    "\n",
    "#Mark the training-validation splits\n",
    "train_i = np.ones((len_X_train,), dtype = int) * -1\n",
    "valid_i = np.zeros((len_X_val,), dtype = int)\n",
    "split_fold = np.concatenate((train_i, valid_i))\n",
    "ps = PredefinedSplit(split_fold)\n",
    "    \n",
    "param_search = GridSearchCV(classifier,\n",
    "                            params, \n",
    "                    scoring=metrics.make_scorer(metrics.f1_score, average='macro'),\n",
    "                                cv=ps,\n",
    "                                return_train_score=True)\n",
    "param_search.fit(X,Y)\n",
    "results = param_search.cv_results_\n",
    "best_params = param_search.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [72, 90]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f51176463227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.006454545454545455\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \"\"\"\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [72, 90]"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = 0.006454545454545455)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "f1 = metrics.f1_score(Y_val, Y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFUNJREFUeJzt3X+M3Hd95/HnyzZORAJH7mJQbMc40TkRCCECewk5VH5eOAukWNdGnNNykKpKTuXCH3BECoWmKAgdooc4VY1UTA/laIE0DQf47lxMWqDtoaSyo0BaO3IwhjaboIsJTkTiQLLO+/6YWWcy3vWOvTM7u/N5PqTRzPczn/nO++Ndv+Yzn/nufFNVSJLasGrcBUiSlo6hL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrImnEX0O/cc8+tzZs3j7sMSVpR7rnnnp9W1bqF+i270N+8eTN79+4ddxmStKIk+cdB+rm8I0kNMfQlqSGGviQ1xNCXpIYMFPpJtiY5kORgkhvnuP8zSb7XvTyQ5LG++1+c5KEkfziswiVJp27Bo3eSrAZuAa4ApoE9SXZW1f7ZPlX1gZ7+7wcu6dvNx4G/HkrFkqTTNshM/1LgYFUdqqqngduAbSfpfzXw5dmNJK8DXgZ8czGFSpIWb5Dj9DcAD/ZsTwOXzdUxycuBC4BvdbdXAZ8G/gPwtkVVuhhf+Qp8//vPbV91Fbz61WMrR5LGZZDQzxxt851YdztwR1Ud626/D9hVVQ8mc+2m+wTJdcB1AJs2bRqgpFN07bVw5AgkUAU//CF88YvDfx5JWuYGWd6ZBs7v2d4IPDxP3+30LO0AlwPXJ/kx8F+B9yT5ZP+DqmpHVU1V1dS6dQv+FfGp++Uv4UMfgmefhde8Bn7+8+E/hyStAIPM9PcAW5JcADxEJ9h/vb9TkouBc4C7Ztuq6jd67r8GmKqqE47+GbmZGVi9unP7rLPgySeXvARJWg4WnOlX1QxwPbAbuB+4var2Jbk5yZU9Xa8Gbquq+ZZ+xmdmBtZ0X9/OOgueeGK89UjSmAz0hWtVtQvY1dd2U9/2xxbYx63AradU3TBUdZZ1ekP/oYeWvAxJWg4m/y9yj3U/U+4NfZd3JDVq8kN/ZqZzbehLUoOhf/bZhr6kZrUX+medBUePdtb5JakxbYY+wFNPjaceSRqjdkPfwzYlNajd0HddX1KDDH1Jakh7oX/22Z1rQ19Sg9oLfWf6khpm6EtSQ9oNfY/ekdSgdkPfmb6kBhn6ktQQQ1+SGtJe6K9d27lt6EtqUHuhn/j1ypKa1V7og6EvqVnthr6HbEpqULuh70xfUoMMfUlqiKEvSQ1pM/Q9T66kRrUZ+s70JTXK0JekhrQb+h6yKalB7Yb+U0/Bs8+OpyZJGpOBQj/J1iQHkhxMcuMc938myfe6lweSPNZtf02Su5LsS3Jfkn8/7AEsaL7QBzh6dMnLkaRxWrNQhySrgVuAK4BpYE+SnVW1f7ZPVX2gp//7gUu6m0eB91TVD5KsB+5JsruqHhvmIE7qZKH/5JPPnTNXkhowyEz/UuBgVR2qqqeB24BtJ+l/NfBlgKp6oKp+0L39MPAIsG5xJZ+i+Q7ZBD/MldScQUJ/A/Bgz/Z0t+0ESV4OXAB8a477LgXWAj+c477rkuxNsvfw4cOD1D24hWb6ktSQQUI/c7TVPH23A3dU1bHn7SA5D/gT4Der6oRPT6tqR1VNVdXUunVDfiMwG/qrVz/XZuhLatQgoT8NnN+zvRF4eJ6+2+ku7cxK8mLg/wAfraq7T6fIRZmZ6QR+el67PDm6pEYNEvp7gC1JLkiylk6w7+zvlORi4Bzgrp62tcBXgS9U1Z8Pp+RTNDPz/KUdcKYvqVkLhn5VzQDXA7uB+4Hbq2pfkpuTXNnT9WrgtqrqXfp5F/BG4JqeQzpfM8T6F2boS9JxCx6yCVBVu4BdfW039W1/bI7H/Snwp4uob/EMfUk6ro2/yO0PfQ/ZlNSoNkPfmb6kRrUZ+mvXdto8ekdSY9oMffDrlSU1ydCXpIYY+pLUkHZD3/PkSmpQu6HvTF9Sgwx9SWpI26HvIZuSGtN26DvTl9QYQ1+SGmLoS1JD2g39s8+Gp56CZ084kZckTaw2Qr/3VImzZr907ejRpa1HksZo8kP/2LH5l3fAJR5JTZn80D/Zmj542Kakphj6zvQlNcTQN/QlNcTQN/QlNaTd0Pc8uZIa1G7oO9OX1CBD39CX1BBD30M2JTXE0HemL6kh7Yb+2rWddkNfUkMGCv0kW5McSHIwyY1z3P+ZJN/rXh5I8ljPfe9N8oPu5b3DLH4g84U++E2bkpozTxo+J8lq4BbgCmAa2JNkZ1Xtn+1TVR/o6f9+4JLu7X8O/B4wBRRwT/exR4Y6ivlUnTz0PTm6pMYMMtO/FDhYVYeq6mngNmDbSfpfDXy5e/vfAndW1c+6QX8nsHUxBZ+S2a9NdqYvScAAM31gA/Bgz/Y0cNlcHZO8HLgA+NZJHrvh1Ms8TTMzneuTzfS/+lV42cuG+7xnnQV/+Zdw4YXD3a8kLdIgoZ852mqevtuBO6rq2Kk8Nsl1wHUAmzZtGqCkAS0U+jfdBN/4xvCeDzrvLj73OfjiF+F3f3e4+5akRRok9KeB83u2NwIPz9N3O/Cf+h775r7Hfqf/QVW1A9gBMDU1Nd8LyqlbKPS3betchm3fPrjjDkNf0rIzyJr+HmBLkguSrKUT7Dv7OyW5GDgHuKuneTfw9iTnJDkHeHu3bWksFPqjctVVcN998IMfLO3zStICFgz9qpoBrqcT1vcDt1fVviQ3J7myp+vVwG1VVT2P/RnwcTovHHuAm7ttS2Ncof+rv9q5/spXlvZ5JWkB6cnoZWFqaqr27t07nJ099BBs3Ag7dsC11w5nn4O67LLOqRqHNRZJOokk91TV1EL9Jvsvcsc104fOEs8998CPf7z0zy1J8zD0R+XXfq1z7RKPpGXE0B+VCy+ESy7pHMUjScvEGNJwCY0z9KGzxPORj8BHPwoveMF4apA0HC95CVx/PaxePe5KFsXQH6Xt2+GTn4RPfGI8zy9puC6/HC69dNxVLIqhP0oXXgiPPz6e55Y0PPfeC697XeeIwBXO0B+1zPVNFJJWlA3drwx7eL4vI1g5/CBXkhaybl1nLd/QX+YMfUnDsGoVnHeeob+s/PSncPHFnW+3nGXoSxqW9esnYk1/ckJ/1Sp44AE4fPi5NkNf0rCsX+9Mf1k544zO9S9/+VyboS9pWAz9ZcbQlzRK69fDkSPw1FPjrmRRJif016zpLPEY+pJGYfawzZ/8ZLx1LNLkhD50ZvuGvqRRWL++c73Cl3gMfUkahKG/DBn6kkbF0F+GzjzT0Jc0Guec05lYGvrLiDN9SaOSTMQfaBn6kjSoCThW39CXpEFt2GDoLyuGvqRRcqa/zBj6kkZp/Xp44gn4+c/HXclpM/QlaVATcNhmG6G/wk9kLGmZMPSXmblCf9WqzkWSFsvQX2bmCn2XdiQNSyuhn2RrkgNJDia5cZ4+70qyP8m+JF/qaf9Ut+3+JH+QjPBM4Ya+pFF60Ys6lxX8B1oLJmKS1cAtwBXANLAnyc6q2t/TZwvwYeANVXUkyUu77f8aeAPw6m7X/wu8CfjOMAdxnKEvadRW+GGbg8z0LwUOVtWhqnoauA3Y1tfnWuCWqjoCUFWPdNsLOBNYC5wBvAD4f8MofE6GvqRRayD0NwAP9mxPd9t6XQRclOS7Se5OshWgqu4Cvg38pHvZXVX39z9BkuuS7E2y93DvOW5PlaEvadQaCP251uCrb3sNsAV4M3A18MdJXpLkXwKvADbSeaF4a5I3nrCzqh1VNVVVU+vWrTuV+p/vjDPg2LHOBTrXHq4paZhmQ7/6Y3BlGCT0p4Hze7Y3Av0vc9PA16vqmar6EXCAzovAvwPurqonquoJ4C+A1y++7Hn0nyfXmb6kYVu/vpMxR46Mu5LTMkgi7gG2JLkAeAjYDvx6X5+v0Znh35rkXDrLPYeAC4Frk/wXOu8Y3gT8tyHVfqLe0H/hCw19ScM3e67cz34WzjtvuPtetw7e+c7h7rPPgolYVTNJrgd2A6uBz1fVviQ3A3uramf3vrcn2Q8cA26oqkeT3AG8Ffh7OktC36iq/zWqwTjTlzRyr3hF5/p3fmf4+77ssvGHPkBV7QJ29bXd1HO7gA92L719jgH/cfFlDsjQlzRqr3oVPPIIPPnk8Pc9m2EjNFmJaOhLWgrr1nUuK9DkfQ0DGPqSNA9DX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jashkhf7atZ1rQ1+S5jRZoZ90gt/Ql6Q5TVboQ2eJ5xe/6Nw29CXpeSYz9J3pS9KcDH1JaoihL0kNMfQlqSGGviQ1ZHJD/9lnocrQl6Qekxv6MzOdbUNfko4z9CWpIZMX+meeaehL0jwmL/Sd6UvSvAYK/SRbkxxIcjDJjfP0eVeS/Un2JflST/umJN9Mcn/3/s3DKX0ehr4kzWvBREyyGrgFuAKYBvYk2VlV+3v6bAE+DLyhqo4keWnPLr4AfKKq7kxyNvDsUEfQz9CXpHkNMtO/FDhYVYeq6mngNmBbX59rgVuq6ghAVT0CkOSVwJqqurPb/kRVHR1a9XMx9CVpXoOE/gbgwZ7t6W5br4uAi5J8N8ndSbb2tD+W5H8muTfJ73ffOYyOoS9J8xok9DNHW/VtrwG2AG8Grgb+OMlLuu2/AnwI+FfAhcA1JzxBcl2SvUn2Hj58eODi52ToS9K8Bgn9aeD8nu2NwMNz9Pl6VT1TVT8CDtB5EZgG7u0uDc0AXwNe2/8EVbWjqqaqamrdunWnM47nnHEGPP00PPNMZ9vQl6TjBgn9PcCWJBckWQtsB3b29fka8BaAJOfSWdY51H3sOUlmk/ytwH5GafY8uUe7Hx0Y+pJ03IKh352hXw/sBu4Hbq+qfUluTnJlt9tu4NEk+4FvAzdU1aNVdYzO0s5fJfl7OktFnxvFQI6bDf0nn+xcG/qSdNxAiVhVu4BdfW039dwu4IPdS/9j7wRevbgyT4GhL0nzmsy/yAVDX5LmYOhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jasjkhr7fsilJJ5jc0HemL0knmPzQXz3aszNK0koy+aHvTF+Sjpu80F+9unMx9CXpBJMX+tCZ7XuOXEk6weSG/ixDX5KOm/zQXzWZQ5Sk0zGZiTgb+mvWQDLeWiRpGZn80JckHWfoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYMFPpJtiY5kORgkhvn6fOuJPuT7Evypb77XpzkoSR/OIyiF2ToS9KcFkzFJKuBW4ArgGlgT5KdVbW/p88W4MPAG6rqSJKX9u3m48BfD6/sBRj6kjSnQWb6lwIHq+pQVT0N3AZs6+tzLXBLVR0BqKpHZu9I8jrgZcA3h1PyAAx9SZrTIKG/AXiwZ3u629brIuCiJN9NcneSrQBJVgGfBm4YRrEDM/QlaU6DpOJcX15Tc+xnC/BmYCPwt0leBbwb2FVVD+Yk34GT5DrgOoBNmzYNUNICDH1JmtMgqTgNnN+zvRF4eI4+d1fVM8CPkhyg8yJwOfArSd4HnA2sTfJEVT3vw+Cq2gHsAJiamup/QTl1Z57ZuTb0Jel5Blne2QNsSXJBkrXAdmBnX5+vAW8BSHIuneWeQ1X1G1W1qao2Ax8CvtAf+CPhTF+S5rRg6FfVDHA9sBu4H7i9qvYluTnJld1uu4FHk+wHvg3cUFWPjqroBRn6kjSngVKxqnYBu/rabuq5XcAHu5f59nErcOvpFHnKDH1JmpN/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjLZob969XjrkKRlZjKnwmvXwqc+Be9857grkaRlZTJDH+CGG8ZdgSQtO5O5vCNJmpOhL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ1JV467heZIcBv7xNB9+LvDTIZazEjjmNjjmNixmzC+vqnULdVp2ob8YSfZW1dS461hKjrkNjrkNSzFml3ckqSGGviQ1ZNJCf8e4CxgDx9wGx9yGkY95otb0JUknN2kzfUnSSazI0E+yNcmBJAeT3DjH/Wck+bPu/X+XZPPSVzlcA4z5g0n2J7kvyV8lefk46hymhcbc0++qJJVkxR/pMciYk7yr+7Pel+RLS13jsA3wu70pybeT3Nv9/X7HOOocliSfT/JIkn+Y5/4k+YPuv8d9SV471AKqakVdgNXAD4ELgbXA94FX9vV5H/BH3dvbgT8bd91LMOa3AC/s3v7tFsbc7fci4G+Au4Gpcde9BD/nLcC9wDnd7ZeOu+4lGPMO4Le7t18J/HjcdS9yzG8EXgv8wzz3vwP4CyDA64G/G+bzr8SZ/qXAwao6VFVPA7cB2/r6bAP+R/f2HcDbkmQJaxy2BcdcVd+uqqPdzbuBjUtc47AN8nMG+DjwKeAXS1nciAwy5muBW6rqCEBVPbLENQ7bIGMu4MXd2/8MeHgJ6xu6qvob4Gcn6bIN+EJ13A28JMl5w3r+lRj6G4AHe7anu21z9qmqGeBx4F8sSXWjMciYe/0WnZnCSrbgmJNcApxfVf97KQsboUF+zhcBFyX5bpK7k2xdsupGY5Axfwx4d5JpYBfw/qUpbWxO9f/7KVmJ58ida8befwjSIH1WkoHHk+TdwBTwppFWNHonHXOSVcBngGuWqqAlMMjPeQ2dJZ4303k397dJXlVVj424tlEZZMxXA7dW1aeTXA78SXfMz46+vLEYaX6txJn+NHB+z/ZGTny7d7xPkjV03hKe7O3UcjfImEnyb4CPAFdW1S+XqLZRWWjMLwJeBXwnyY/prH3uXOEf5g76u/31qnqmqn4EHKDzIrBSDTLm3wJuB6iqu4Az6XxHzaQa6P/76VqJob8H2JLkgiRr6XxQu7Ovz07gvd3bVwHfqu4nJCvUgmPuLnV8lk7gr/R1XlhgzFX1eFWdW1Wbq2oznc8xrqyqveMpdygG+d3+Gp0P7UlyLp3lnkNLWuVwDTLmfwLeBpDkFXRC//CSVrm0dgLv6R7F83rg8ar6ybB2vuKWd6pqJsn1wG46n/x/vqr2JbkZ2FtVO4H/Tuct4EE6M/zt46t48QYc8+8DZwN/3v3M+p+q6sqxFb1IA455ogw45t3A25PsB44BN1TVo+OrenEGHPN/Bj6X5AN0ljmuWcmTuCRfprM8d273c4rfA14AUFV/ROdzi3cAB4GjwG8O9flX8L+dJOkUrcTlHUnSaTL0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyP8HxtyFWE+OiEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores = results.get('split0_test_score')\n",
    "par_ranges = params.values()\n",
    "\n",
    "plt.plot(list(par_ranges)[0],test_scores,'r-')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.021181818181818184}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.44980407, 0.00243759, 0.00242901, 0.00242066, 0.00253463,\n",
       "        0.00250244, 0.0027225 , 0.0027082 , 0.00292468, 0.00241351,\n",
       "        0.00243044, 0.00170183, 0.0016408 , 0.00125837, 0.00137591,\n",
       "        0.00105977, 0.00104427, 0.00103283, 0.00092673, 0.00089979,\n",
       "        0.00092793, 0.00153971, 0.00105453, 0.00105381, 0.00101089,\n",
       "        0.00090146, 0.00097847, 0.00115967, 0.00098228, 0.00101018,\n",
       "        0.00100899, 0.00113106, 0.00103402, 0.00096703, 0.00088286,\n",
       "        0.00088048, 0.00097299, 0.00124073, 0.00100064, 0.00097346,\n",
       "        0.00114346, 0.00112081, 0.00108671, 0.00095606, 0.0008924 ,\n",
       "        0.00084829, 0.00093341, 0.00115752, 0.00116372, 0.00102305,\n",
       "        0.00126982, 0.00100803, 0.00117064, 0.0008831 , 0.00108719,\n",
       "        0.00110507, 0.00103498, 0.00102234, 0.00096631, 0.00076723,\n",
       "        0.00077558, 0.00076723, 0.00072956, 0.0007143 , 0.00072479,\n",
       "        0.00071621, 0.00074863, 0.00074553, 0.00072646, 0.00071192,\n",
       "        0.00072241, 0.00079346, 0.0007515 , 0.00075436, 0.00076652,\n",
       "        0.00140834, 0.00085998, 0.00080705, 0.00088573, 0.00075293,\n",
       "        0.00070286, 0.00075436, 0.0007782 , 0.00128984, 0.00087357,\n",
       "        0.00103045, 0.00087547, 0.00094676, 0.00118256, 0.00079441,\n",
       "        0.00075197, 0.00070977, 0.00070763, 0.00077534, 0.00141931,\n",
       "        0.00116181, 0.00122237, 0.00128436, 0.00085688, 0.00108004]),\n",
       " 'std_fit_time': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'mean_score_time': array([0.0318439 , 0.00170135, 0.00165701, 0.00167465, 0.002321  ,\n",
       "        0.00172734, 0.00170612, 0.00167322, 0.00178981, 0.00164843,\n",
       "        0.0018878 , 0.0011425 , 0.00112486, 0.00086021, 0.00092673,\n",
       "        0.00069976, 0.0007391 , 0.00072169, 0.00058818, 0.00059438,\n",
       "        0.00063062, 0.00098825, 0.00082016, 0.00067711, 0.00068545,\n",
       "        0.00060654, 0.00076389, 0.000736  , 0.00063467, 0.00069213,\n",
       "        0.00072265, 0.0007391 , 0.00079513, 0.00063634, 0.0005827 ,\n",
       "        0.00070858, 0.00067258, 0.00073171, 0.00066495, 0.00069427,\n",
       "        0.00089312, 0.00083375, 0.00065327, 0.00062919, 0.00058413,\n",
       "        0.00063992, 0.00066113, 0.00074506, 0.00074553, 0.00068617,\n",
       "        0.00076127, 0.00076413, 0.00136805, 0.00064516, 0.000772  ,\n",
       "        0.00072885, 0.00072694, 0.00058389, 0.00065255, 0.00053692,\n",
       "        0.0005343 , 0.00059509, 0.00048852, 0.00048518, 0.00048614,\n",
       "        0.00049233, 0.00051785, 0.00049996, 0.00048971, 0.00049162,\n",
       "        0.00063467, 0.00066304, 0.00061679, 0.00062442, 0.00064921,\n",
       "        0.00070143, 0.00069356, 0.00052404, 0.00057459, 0.00049329,\n",
       "        0.00049257, 0.00053287, 0.00065517, 0.00073767, 0.00068569,\n",
       "        0.00061655, 0.0006671 , 0.00058794, 0.00084043, 0.00058699,\n",
       "        0.00049138, 0.0004766 , 0.00057077, 0.00051785, 0.00088096,\n",
       "        0.00078511, 0.00078177, 0.00082922, 0.00053573, 0.00067735]),\n",
       " 'std_score_time': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.001090909090909091, 0.0011818181818181819,\n",
       "                    0.0012727272727272728, 0.0013636363636363637,\n",
       "                    0.0014545454545454547, 0.0015454545454545456,\n",
       "                    0.0016363636363636363, 0.0017272727272727275,\n",
       "                    0.0018181818181818182, 0.0019090909090909093, 0.002,\n",
       "                    0.002090909090909091, 0.002181818181818182,\n",
       "                    0.0022727272727272726, 0.0023636363636363638,\n",
       "                    0.002454545454545455, 0.0025454545454545456,\n",
       "                    0.0026363636363636363, 0.0027272727272727275,\n",
       "                    0.0028181818181818186, 0.0029090909090909093, 0.003,\n",
       "                    0.003090909090909091, 0.003181818181818182,\n",
       "                    0.003272727272727273, 0.003363636363636364,\n",
       "                    0.003454545454545455, 0.0035454545454545456,\n",
       "                    0.003636363636363637, 0.0037272727272727275,\n",
       "                    0.0038181818181818187, 0.003909090909090909, 0.004,\n",
       "                    0.004090909090909091, 0.004181818181818182,\n",
       "                    0.0042727272727272735, 0.004363636363636364,\n",
       "                    0.004454545454545455, 0.004545454545454545,\n",
       "                    0.004636363636363636, 0.0047272727272727275,\n",
       "                    0.004818181818181819, 0.00490909090909091, 0.005,\n",
       "                    0.005090909090909091, 0.005181818181818182,\n",
       "                    0.0052727272727272735, 0.005363636363636364,\n",
       "                    0.005454545454545455, 0.005545454545454546,\n",
       "                    0.005636363636363636, 0.0057272727272727275,\n",
       "                    0.005818181818181819, 0.00590909090909091, 0.006,\n",
       "                    0.006090909090909091, 0.006181818181818182,\n",
       "                    0.006272727272727274, 0.006363636363636364,\n",
       "                    0.006454545454545455, 0.006545454545454546,\n",
       "                    0.006636363636363637, 0.006727272727272728,\n",
       "                    0.006818181818181819, 0.00690909090909091, 0.007,\n",
       "                    0.007090909090909091, 0.0071818181818181824,\n",
       "                    0.007272727272727274, 0.007363636363636364,\n",
       "                    0.007454545454545455, 0.007545454545454546,\n",
       "                    0.007636363636363637, 0.007727272727272728,\n",
       "                    0.007818181818181818, 0.00790909090909091, 0.008,\n",
       "                    0.008090909090909091, 0.008181818181818182,\n",
       "                    0.008272727272727274, 0.008363636363636365,\n",
       "                    0.008454545454545454, 0.008545454545454547,\n",
       "                    0.008636363636363636, 0.008727272727272728,\n",
       "                    0.008818181818181819, 0.008909090909090908,\n",
       "                    0.009000000000000001, 0.00909090909090909,\n",
       "                    0.009181818181818183, 0.009272727272727273,\n",
       "                    0.009363636363636366, 0.009454545454545455,\n",
       "                    0.009545454545454548, 0.009636363636363637,\n",
       "                    0.009727272727272727, 0.00981818181818182,\n",
       "                    0.009909090909090909, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.001},\n",
       "  {'alpha': 0.001090909090909091},\n",
       "  {'alpha': 0.0011818181818181819},\n",
       "  {'alpha': 0.0012727272727272728},\n",
       "  {'alpha': 0.0013636363636363637},\n",
       "  {'alpha': 0.0014545454545454547},\n",
       "  {'alpha': 0.0015454545454545456},\n",
       "  {'alpha': 0.0016363636363636363},\n",
       "  {'alpha': 0.0017272727272727275},\n",
       "  {'alpha': 0.0018181818181818182},\n",
       "  {'alpha': 0.0019090909090909093},\n",
       "  {'alpha': 0.002},\n",
       "  {'alpha': 0.002090909090909091},\n",
       "  {'alpha': 0.002181818181818182},\n",
       "  {'alpha': 0.0022727272727272726},\n",
       "  {'alpha': 0.0023636363636363638},\n",
       "  {'alpha': 0.002454545454545455},\n",
       "  {'alpha': 0.0025454545454545456},\n",
       "  {'alpha': 0.0026363636363636363},\n",
       "  {'alpha': 0.0027272727272727275},\n",
       "  {'alpha': 0.0028181818181818186},\n",
       "  {'alpha': 0.0029090909090909093},\n",
       "  {'alpha': 0.003},\n",
       "  {'alpha': 0.003090909090909091},\n",
       "  {'alpha': 0.003181818181818182},\n",
       "  {'alpha': 0.003272727272727273},\n",
       "  {'alpha': 0.003363636363636364},\n",
       "  {'alpha': 0.003454545454545455},\n",
       "  {'alpha': 0.0035454545454545456},\n",
       "  {'alpha': 0.003636363636363637},\n",
       "  {'alpha': 0.0037272727272727275},\n",
       "  {'alpha': 0.0038181818181818187},\n",
       "  {'alpha': 0.003909090909090909},\n",
       "  {'alpha': 0.004},\n",
       "  {'alpha': 0.004090909090909091},\n",
       "  {'alpha': 0.004181818181818182},\n",
       "  {'alpha': 0.0042727272727272735},\n",
       "  {'alpha': 0.004363636363636364},\n",
       "  {'alpha': 0.004454545454545455},\n",
       "  {'alpha': 0.004545454545454545},\n",
       "  {'alpha': 0.004636363636363636},\n",
       "  {'alpha': 0.0047272727272727275},\n",
       "  {'alpha': 0.004818181818181819},\n",
       "  {'alpha': 0.00490909090909091},\n",
       "  {'alpha': 0.005},\n",
       "  {'alpha': 0.005090909090909091},\n",
       "  {'alpha': 0.005181818181818182},\n",
       "  {'alpha': 0.0052727272727272735},\n",
       "  {'alpha': 0.005363636363636364},\n",
       "  {'alpha': 0.005454545454545455},\n",
       "  {'alpha': 0.005545454545454546},\n",
       "  {'alpha': 0.005636363636363636},\n",
       "  {'alpha': 0.0057272727272727275},\n",
       "  {'alpha': 0.005818181818181819},\n",
       "  {'alpha': 0.00590909090909091},\n",
       "  {'alpha': 0.006},\n",
       "  {'alpha': 0.006090909090909091},\n",
       "  {'alpha': 0.006181818181818182},\n",
       "  {'alpha': 0.006272727272727274},\n",
       "  {'alpha': 0.006363636363636364},\n",
       "  {'alpha': 0.006454545454545455},\n",
       "  {'alpha': 0.006545454545454546},\n",
       "  {'alpha': 0.006636363636363637},\n",
       "  {'alpha': 0.006727272727272728},\n",
       "  {'alpha': 0.006818181818181819},\n",
       "  {'alpha': 0.00690909090909091},\n",
       "  {'alpha': 0.007},\n",
       "  {'alpha': 0.007090909090909091},\n",
       "  {'alpha': 0.0071818181818181824},\n",
       "  {'alpha': 0.007272727272727274},\n",
       "  {'alpha': 0.007363636363636364},\n",
       "  {'alpha': 0.007454545454545455},\n",
       "  {'alpha': 0.007545454545454546},\n",
       "  {'alpha': 0.007636363636363637},\n",
       "  {'alpha': 0.007727272727272728},\n",
       "  {'alpha': 0.007818181818181818},\n",
       "  {'alpha': 0.00790909090909091},\n",
       "  {'alpha': 0.008},\n",
       "  {'alpha': 0.008090909090909091},\n",
       "  {'alpha': 0.008181818181818182},\n",
       "  {'alpha': 0.008272727272727274},\n",
       "  {'alpha': 0.008363636363636365},\n",
       "  {'alpha': 0.008454545454545454},\n",
       "  {'alpha': 0.008545454545454547},\n",
       "  {'alpha': 0.008636363636363636},\n",
       "  {'alpha': 0.008727272727272728},\n",
       "  {'alpha': 0.008818181818181819},\n",
       "  {'alpha': 0.008909090909090908},\n",
       "  {'alpha': 0.009000000000000001},\n",
       "  {'alpha': 0.00909090909090909},\n",
       "  {'alpha': 0.009181818181818183},\n",
       "  {'alpha': 0.009272727272727273},\n",
       "  {'alpha': 0.009363636363636366},\n",
       "  {'alpha': 0.009454545454545455},\n",
       "  {'alpha': 0.009545454545454548},\n",
       "  {'alpha': 0.009636363636363637},\n",
       "  {'alpha': 0.009727272727272727},\n",
       "  {'alpha': 0.00981818181818182},\n",
       "  {'alpha': 0.009909090909090909},\n",
       "  {'alpha': 0.01}],\n",
       " 'split0_test_score': array([0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444]),\n",
       " 'mean_test_score': array([0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.45625   , 0.45625   , 0.45625   , 0.45625   , 0.45625   ,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444,\n",
       "        0.49444444, 0.49444444, 0.49444444, 0.49444444, 0.49444444]),\n",
       " 'std_test_score': array([5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        5.55111512e-17, 5.55111512e-17, 5.55111512e-17, 5.55111512e-17,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'rank_test_score': array([41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "        41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "        41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "        41, 41, 41, 41, 41, 41, 41, 41, 41,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'std_train_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C000016',\n",
       " 'C000013',\n",
       " 'C000008',\n",
       " 'C000022',\n",
       " 'C000013',\n",
       " 'C000010',\n",
       " 'C000010',\n",
       " 'C000022',\n",
       " 'C000020',\n",
       " 'C000022',\n",
       " 'C000024',\n",
       " 'C000010',\n",
       " 'C000023',\n",
       " 'C000022',\n",
       " 'C000024',\n",
       " 'C000023',\n",
       " 'C000014',\n",
       " 'C000010',\n",
       " 'C000014',\n",
       " 'C000008',\n",
       " 'C000024',\n",
       " 'C000013',\n",
       " 'C000008',\n",
       " 'C000013',\n",
       " 'C000016',\n",
       " 'C000016',\n",
       " 'C000013',\n",
       " 'C000013',\n",
       " 'C000024',\n",
       " 'C000014',\n",
       " 'C000008',\n",
       " 'C000010',\n",
       " 'C000024',\n",
       " 'C000020',\n",
       " 'C000020',\n",
       " 'C000023',\n",
       " 'C000024',\n",
       " 'C000022',\n",
       " 'C000016',\n",
       " 'C000013',\n",
       " 'C000016',\n",
       " 'C000014',\n",
       " 'C000023',\n",
       " 'C000010',\n",
       " 'C000014',\n",
       " 'C000020',\n",
       " 'C000014',\n",
       " 'C000016',\n",
       " 'C000024',\n",
       " 'C000020',\n",
       " 'C000008',\n",
       " 'C000013',\n",
       " 'C000023',\n",
       " 'C000008',\n",
       " 'C000024',\n",
       " 'C000023',\n",
       " 'C000014',\n",
       " 'C000022',\n",
       " 'C000014',\n",
       " 'C000020',\n",
       " 'C000016',\n",
       " 'C000016',\n",
       " 'C000013',\n",
       " 'C000016',\n",
       " 'C000022',\n",
       " 'C000008',\n",
       " 'C000020',\n",
       " 'C000020',\n",
       " 'C000010',\n",
       " 'C000023',\n",
       " 'C000023',\n",
       " 'C000024',\n",
       " 'C000008',\n",
       " 'C000023',\n",
       " 'C000022',\n",
       " 'C000020',\n",
       " 'C000022',\n",
       " 'C000013',\n",
       " 'C000014',\n",
       " 'C000022',\n",
       " 'C000010',\n",
       " 'C000016',\n",
       " 'C000008',\n",
       " 'C000010',\n",
       " 'C000024',\n",
       " 'C000008',\n",
       " 'C000010',\n",
       " 'C000023',\n",
       " 'C000020',\n",
       " 'C000014']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=list(train_class_list)\n",
    "c=list(test_class_list)\n",
    "m.extend(c)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C000016',\n",
       " 'C000013',\n",
       " 'C000008',\n",
       " 'C000020',\n",
       " 'C000013',\n",
       " 'C000014',\n",
       " 'C000008',\n",
       " 'C000008',\n",
       " 'C000014',\n",
       " 'C000020',\n",
       " 'C000024',\n",
       " 'C000016',\n",
       " 'C000016',\n",
       " 'C000016',\n",
       " 'C000020',\n",
       " 'C000016',\n",
       " 'C000013',\n",
       " 'C000022',\n",
       " 'C000014',\n",
       " 'C000022',\n",
       " 'C000010',\n",
       " 'C000016',\n",
       " 'C000014',\n",
       " 'C000014',\n",
       " 'C000008',\n",
       " 'C000022',\n",
       " 'C000020',\n",
       " 'C000008',\n",
       " 'C000016',\n",
       " 'C000023',\n",
       " 'C000016',\n",
       " 'C000020',\n",
       " 'C000008',\n",
       " 'C000024',\n",
       " 'C000020',\n",
       " 'C000022',\n",
       " 'C000022',\n",
       " 'C000023',\n",
       " 'C000020',\n",
       " 'C000010',\n",
       " 'C000024',\n",
       " 'C000008',\n",
       " 'C000022',\n",
       " 'C000020',\n",
       " 'C000014',\n",
       " 'C000023',\n",
       " 'C000010',\n",
       " 'C000024',\n",
       " 'C000022',\n",
       " 'C000024',\n",
       " 'C000020',\n",
       " 'C000020',\n",
       " 'C000014',\n",
       " 'C000014',\n",
       " 'C000024',\n",
       " 'C000016',\n",
       " 'C000023',\n",
       " 'C000013',\n",
       " 'C000010',\n",
       " 'C000014',\n",
       " 'C000023',\n",
       " 'C000023',\n",
       " 'C000010',\n",
       " 'C000008',\n",
       " 'C000010',\n",
       " 'C000013',\n",
       " 'C000024',\n",
       " 'C000023',\n",
       " 'C000023',\n",
       " 'C000013',\n",
       " 'C000013',\n",
       " 'C000008',\n",
       " 'C000023',\n",
       " 'C000022',\n",
       " 'C000010',\n",
       " 'C000010',\n",
       " 'C000013',\n",
       " 'C000008',\n",
       " 'C000010',\n",
       " 'C000024',\n",
       " 'C000023',\n",
       " 'C000013',\n",
       " 'C000014',\n",
       " 'C000022',\n",
       " 'C000013',\n",
       " 'C000010',\n",
       " 'C000022',\n",
       " 'C000024',\n",
       " 'C000024',\n",
       " 'C000016']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C000008', 'C000013', 'C000024', 'C000022', 'C000020', 'C000016',\n",
       "       'C000016', 'C000013', 'C000024', 'C000023', 'C000023', 'C000023',\n",
       "       'C000014', 'C000014', 'C000020', 'C000020', 'C000016', 'C000008',\n",
       "       'C000010', 'C000014', 'C000016', 'C000022', 'C000010', 'C000014',\n",
       "       'C000020', 'C000008', 'C000023', 'C000016', 'C000010', 'C000023',\n",
       "       'C000020', 'C000013', 'C000023', 'C000016', 'C000023', 'C000010',\n",
       "       'C000022', 'C000022', 'C000013', 'C000014', 'C000013', 'C000010',\n",
       "       'C000024', 'C000022', 'C000020', 'C000022', 'C000014', 'C000020',\n",
       "       'C000010', 'C000024', 'C000024', 'C000022', 'C000014', 'C000008',\n",
       "       'C000024', 'C000014', 'C000010', 'C000024', 'C000008', 'C000020',\n",
       "       'C000014', 'C000008', 'C000010', 'C000013', 'C000008', 'C000023',\n",
       "       'C000024', 'C000022', 'C000010', 'C000020', 'C000023', 'C000008',\n",
       "       'C000016', 'C000016', 'C000023', 'C000013', 'C000016', 'C000024',\n",
       "       'C000008', 'C000010', 'C000024', 'C000022', 'C000008', 'C000016',\n",
       "       'C000020', 'C000014', 'C000022', 'C000013', 'C000013', 'C000013'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.vstack([train_feature_list,test_feature_list])\n",
    "    #np.vstack((a,b))\n",
    "    #Y_train.extend(Y_val)\n",
    "    #Y = np.array(Y_train)\n",
    "Y = np.append(train_class_list,test_class_list)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= np.ones((train_feature_list.shape[0],1000), dtype = int)*-1\n",
    "d= np.zeros((test_feature_list.shape[0],1000), dtype = int)\n",
    "\n",
    "split_fold = np.concatenate((c,d))\n",
    "split_fold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C000023',\n",
       " 'C000013',\n",
       " 'C000024',\n",
       " 'C000022',\n",
       " 'C000008',\n",
       " 'C000020',\n",
       " 'C000014',\n",
       " 'C000016',\n",
       " 'C000010']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tuning(X_train, Y_train, X_val, Y_val, classifier , params):\n",
    "    '''\n",
    "    Tunes hyperparameters by running the classifier trained using training data\n",
    "    on the range of parameters given, and returns the parameters which give the\n",
    "    best f1-score on test data\n",
    "    '''\n",
    "    #Combine training and validation into one set\n",
    "    X = vstack([X_train,X_val])\n",
    "    #np.vstack((a,b))\n",
    "    #Y_train.extend(Y_val)\n",
    "    #Y = np.array(Y_train)\n",
    "    Y = np.append(Y_train,Y_val)\n",
    "    \n",
    "    #Mark the training-validation splits\n",
    "    train_i = np.ones((X_train.shape[0],1000), dtype = int) * -1\n",
    "    valid_i = np.zeros((X_val.shape[0],1), dtype = int)\n",
    "    split_fold = np.concatenate((train_i, valid_i))\n",
    "    ps = PredefinedSplit(split_fold)\n",
    "    \n",
    "    param_search = GridSearchCV(classifier, params, scoring=metrics.make_scorer(metrics.f1_score, average='macro'), cv=ps, return_train_score=True)\n",
    "    param_search.fit(X,Y)\n",
    "    results = param_search.cv_results_\n",
    "    best_params = param_search.best_params_\n",
    "    '''\n",
    "    #Plotting\n",
    "    test_scores = results.get('split0_test_score')\n",
    "    par_ranges = params.values()\n",
    "    plt.plot(par_ranges[0],test_scores,'r-')\n",
    "    plt.show\n",
    "    '''\n",
    "    return best_params, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c2bd02e8627a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mtest_class_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_class_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mbest_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_class_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_feature_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_class_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_NB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0;31m#best_alpha, results = tuning(X_trainf, Y_trainf, X_valf, Y_valf, MultinomialNB(), params_NB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c2bd02e8627a>\u001b[0m in \u001b[0;36mtuning\u001b[0;34m(X_train, Y_train, X_val, Y_val, classifier, params)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;31m#np.vstack((a,b))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m#Y_train.extend(Y_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    420\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[1;32m    421\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "#coding: utf-8\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import jieba\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "#######################################\n",
    "#                tuning               #\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "\n",
    "\n",
    "def MakeWordsSet(words_file):\n",
    "    \"\"\"\n",
    "    函数说明:读取文件里的内容，并去重\n",
    "    Parameters:\n",
    "        words_file - 文件路径\n",
    "    Returns:\n",
    "        words_set - 读取的内容的set集合\n",
    "    \"\"\"\n",
    "    words_set = set()\n",
    "    with open(words_file, 'r') as fp:\n",
    "        for line in fp.readlines():\n",
    "            word = line.strip()#.decode(\"utf-8\")\n",
    "            if len(word)>0 and word not in words_set: # 去重\n",
    "                words_set.add(word)\n",
    "    return words_set\n",
    "\n",
    "def TextProcessing(folder_path, test_size=0.2):\n",
    "    \"\"\"\n",
    "    函数说明:中文文本处理\n",
    "    Parameters:\n",
    "        folder_path - 文本存放的路径\n",
    "        test_size - 测试集占比，默认占所有数据集的百分之20\n",
    "    Returns:\n",
    "        all_words_list - 按词频降序排序的训练集列表\n",
    "        train_data_list - 训练集列表\n",
    "        test_data_list - 测试集列表\n",
    "        train_class_list - 训练集标签列表\n",
    "        test_class_list - 测试集标签列表\n",
    "    \"\"\"\n",
    "    folder_list = os.listdir(folder_path)\n",
    "    data_list = []\n",
    "    class_list = []\n",
    "\n",
    "    # 类间循环\n",
    "    for folder in folder_list:\n",
    "        new_folder_path = os.path.join(folder_path, folder)\n",
    "        files = os.listdir(new_folder_path)\n",
    "        # 类内循环\n",
    "        j = 1\n",
    "        for file in files:\n",
    "            if j > 100: # 每类text样本数最多100\n",
    "                break\n",
    "            with open(os.path.join(new_folder_path, file), 'r') as fp:\n",
    "               raw = fp.read()\n",
    "           \n",
    "            word_cut = jieba.cut(raw, cut_all=False) # 精确模式，返回的结构是一个可迭代的genertor\n",
    "            word_list = list(word_cut) # genertor转化为list，每个词unicode格式\n",
    "          \n",
    "            data_list.append(word_list)\n",
    "            class_list.append(folder)#.decode('utf-8')\n",
    "            j += 1\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    data_class_list = list(zip(data_list, class_list))\n",
    "    random.shuffle(data_class_list)\n",
    "    index = int(len(data_class_list)*test_size)+1\n",
    "    train_list = data_class_list[index:]\n",
    "    test_list = data_class_list[:index]\n",
    "    train_data_list, train_class_list = zip(*train_list)\n",
    "    test_data_list, test_class_list = zip(*test_list)\n",
    "\n",
    "    # 统计词频放入all_words_dict\n",
    "    all_words_dict = {} \n",
    "    for word_list in train_data_list:\n",
    "        for word in word_list:\n",
    "            #if all_words_dict.has_key(word):\n",
    "            if word in all_words_dict.keys():\n",
    "                all_words_dict[word] += 1\n",
    "            else:\n",
    "                all_words_dict[word] = 1\n",
    "\n",
    "    # 根据键的值倒序排序\n",
    "    all_words_tuple_list = sorted(all_words_dict.items(), key=lambda f:f[1], reverse=True) # 内建函数sorted参数需为list\n",
    "    all_words_list = list(zip(all_words_tuple_list))[0]\n",
    "\n",
    "    return all_words_list, train_data_list, test_data_list, train_class_list, test_class_list\n",
    "\n",
    "def words_dict(all_words_list, deleteN, stopwords_set=set()):\n",
    "    \"\"\"\n",
    "    函数说明:文本特征选取\n",
    "    Parameters:\n",
    "        all_words_list - 训练集所有文本列表\n",
    "        deleteN - 删除词频最高的deleteN个词\n",
    "        stopwords_set - 指定的结束语\n",
    "    Returns:\n",
    "        feature_words - 特征集\n",
    "    \"\"\"\n",
    "    # 选取特征词\n",
    "    feature_words = []\n",
    "    n = 1\n",
    "    for t in range(deleteN, len(all_words_list), 1):\n",
    "        if n > 1000: # feature_words的维度1000\n",
    "            break\n",
    "        # 如果这个词不是数字，并且不是指定的结束语，并且单词长度大于1小于5，那么这个词就可以作为feature_word\n",
    "        if not all_words_list[t].isdigit() and all_words_list[t] not in stopwords_set and 1<len(all_words_list[t])<5:\n",
    "            feature_words.append(all_words_list[t])\n",
    "            n += 1\n",
    "    return feature_words\n",
    "\n",
    "def TextFeatures(train_data_list, test_data_list, feature_words):\n",
    "    \"\"\"\n",
    "    函数说明:根据feature_words将文本向量化\n",
    "    Parameters:\n",
    "        train_data_list - 训练集\n",
    "        test_data_list - 测试集\n",
    "        feature_words - 特征集\n",
    "    Returns:\n",
    "        train_feature_list - 训练集向量化列表\n",
    "        test_feature_list - 测试集向量化列表\n",
    "    \"\"\"\n",
    "    def text_features(text, feature_words):\n",
    "        text_words = set(text)\n",
    "        features = [1 if word in text_words else 0 for word in feature_words]\n",
    "        return features\n",
    "    train_feature_list = [text_features(text, feature_words) for text in train_data_list]\n",
    "    test_feature_list = [text_features(text, feature_words) for text in test_data_list]\n",
    "    return train_feature_list, test_feature_list\n",
    "\n",
    "def TextClassifier(train_feature_list, test_feature_list, train_class_list, test_class_list):\n",
    "    \"\"\"\n",
    "    函数说明:分类器\n",
    "    Parameters:\n",
    "        train_feature_list - 训练集向量化的特征文本\n",
    "        test_feature_list - 测试集向量化的特征文本\n",
    "        train_class_list - 训练集分类标签\n",
    "        test_class_list - 测试集分类标签\n",
    "    Returns:\n",
    "        test_accuracy - 分类器精度\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "        请编写这部分代码\n",
    "\n",
    "    \"\"\"\n",
    "    #pass\n",
    "    \n",
    "    #return test_accuracy\n",
    "def tuning(X_train, Y_train, X_val, Y_val, classifier , params):\n",
    "    '''\n",
    "    Tunes hyperparameters by running the classifier trained using training data\n",
    "    on the range of parameters given, and returns the parameters which give the\n",
    "    best f1-score on test data\n",
    "    '''\n",
    "    #Combine training and validation into one set\n",
    "    #X = vstack([X_train,X_val])\n",
    "    \n",
    "    #np.vstack((a,b))\n",
    "    Y_train.extend(Y_val)\n",
    "    #Y = np.array(Y_train)\n",
    "    Y = np.append(Y_train,Y_val)\n",
    "    #Mark the training-validation splits\n",
    "    train_i = np.ones((X_train.shape[0],), dtype = int) * -1\n",
    "    valid_i = np.zeros((X_val.shape[0],), dtype = int)\n",
    "    #split_fold = np.concatenate((train_i, valid_i))\n",
    "    #ps = PredefinedSplit(split_fold)\n",
    "    \n",
    "    param_search = GridSearchCV(classifier, params, \n",
    "                    scoring=metrics.make_scorer(metrics.f1_score, average='macro'),\n",
    "                                cv=None,\n",
    "                                return_train_score=True)\n",
    "    param_search.fit(X,Y)\n",
    "    results = param_search.cv_results_\n",
    "    best_params = param_search.best_params_\n",
    "    '''\n",
    "    #Plotting\n",
    "    test_scores = results.get('split0_test_score')\n",
    "    par_ranges = params.values()\n",
    "    plt.plot(par_ranges[0],test_scores,'r-')\n",
    "    plt.show\n",
    "    '''\n",
    "    return best_params, results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 文本预处理\n",
    "    folder_path = './Database/SogouC/Sample'\n",
    "    all_words_list, train_data_list, test_data_list, train_class_list, test_class_list = TextProcessing(folder_path, test_size=0.2)\n",
    "\n",
    "    # 生成stopwords_set\n",
    "    stopwords_file = './stopwords_cn.txt'\n",
    "    stopwords_set = MakeWordsSet(stopwords_file)\n",
    "\n",
    "    # 文本特征提取和分类\n",
    "    deleteN = 450\n",
    "    feature_words = words_dict(all_words_list, deleteN, stopwords_set)\n",
    "    train_feature_list, test_feature_list = TextFeatures(train_data_list, test_data_list, feature_words)\n",
    "\n",
    "    # HyperParamater Tuning \n",
    "    params_NB = {'alpha':np.linspace(0.001,0.01,100)}\n",
    "    \n",
    "    train_feature_list = list(train_feature_list)\n",
    "    train_class_list = list(train_class_list)\n",
    "    test_feature_list = list(test_feature_list)\n",
    "    test_class_list = list(test_class_list)\n",
    "    '''\n",
    "    train_feature_list = np.array(train_feature_list)\n",
    "    train_class_list = np.array(train_class_list)\n",
    "    test_feature_list = np.array(test_feature_list)\n",
    "    test_class_list = np.array(test_class_list)\n",
    "    '''\n",
    "    best_alpha, results = tuning(train_feature_list,train_class_list,test_feature_list,test_class_list, MultinomialNB(), params_NB)\n",
    "    #best_alpha, results = tuning(X_trainf, Y_trainf, X_valf, Y_valf, MultinomialNB(), params_NB)\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'append' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-86acedf7a0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'append' is not defined"
     ]
    }
   ],
   "source": [
    "x = [[1,2],[1,2]]\n",
    "y = [[3,2],[5,2]]\n",
    "append(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
