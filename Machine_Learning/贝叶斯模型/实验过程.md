
# <center>机器学习实验报告<center>

  <br/><br/><br/><br/>

  <br/><br/><br/><br/>

### <center>姓名：杨崇焕
### <center>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;学号：U201610531
### <center>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;班级：电信中英1601
### <center>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实验内容：贝叶斯网络

<div STYLE="page-break-after: always;"></div>

### 一.实验目的：
>使用贝叶斯网络来完成如下三个分类预测问题。
​	　任务一：使用朴素贝叶斯过滤垃圾邮件
​	　任务二：使用朴素贝叶斯对搜狗新闻语料库进行分类
​	　任务三：使用朴素贝叶斯对电影评论分类
### 二.实验原理：
> 朴素贝叶斯分类器：采用**属性条件独立性假设**：对已知类别，假设所有属性相互独立，即假设每个属性独立地分类结果结果产生影响。基于属性条件独立性假设，贝叶斯公式可以写为：
>$$p(c|\vec{x})=\frac{p(c)p(\vec{x}|c)}{p(x)}=\frac{p(c)}{p(\vec{x})}\prod_{i=0}^dp(\vec{x}|c)
$$
则朴素贝叶斯分类器：
$$
h_{nb}(x)=arg\,\max_{c\in\gamma}p(c)\prod_{i=0}^dp(x_i|c)
$$
朴素贝叶斯分类器的训练过程就是基于训练集 D 来估计类先验概率 P(c)，并为每个属性估计条件概率
### 三.实验过程：
#### &emsp;&emsp;实验环境：
> - ubuntu 18.04
>- python 3.6
>- numpy 1.14.3
>- pandas 0.23.0
>- scikit-learn 0.19.1
>- jieba
#### &emsp;&emsp;任务一：使用朴素贝叶斯过滤垃圾邮件
#### &emsp;&emsp;实验原理：
> &emsp;&emsp;**词袋模型**：用所有文本组成一个词库，单个文本的向量的值对应词库中该词出现的1位置及其在全部文本中出现的次数

#### &emsp;&emsp;实验步骤：
> **数据处理**：利用bag of words处理文本得到文本向量, 并采用交叉验证的方式从数据集中随机抽取10个作为测试集，其余40个为训练集。
> **训练**：构建一个二分类朴素贝叶斯训练函数，并计算每个属性估计条件概率
> **测试**：将测试集带入训练好的模型中即可得到结果

#### &emsp;&emsp;实验具体实现：
##### &emsp;&emsp;&emsp;1.获取文本及词库：
```python
    #获取spam，ham文本
    #将每个文本的数据作为string记录在docList
    #将类标签保存在classList中
    docList = []; classList = []
    for i in range(1, 26):
        wordList = textParse(open('./spam/%d.txt' % i, encoding="ISO-8859-1").read())
        docList.append(wordList)
        classList.append(1)

        wordList = textParse(open('./ham/%d.txt' % i, encoding="ISO-8859-1").read())
        docList.append(wordList)
        classList.append(0)
    #得到词库
    vocabList = createVocabList(docList)
```
##### &emsp;&emsp;&emsp;2.采用生成随机检索数的方法划分数据集及测试集：
```python
    #创建训练集及测试集
    trainingSet = range(50); testSet = []
    for i in range(10):
        randIndex = int(np.random.uniform(0, len(trainingSet)))
        testSet.append(trainingSet[randIndex])
        #从原数据集中删除测试集即得到训练集
        del(list(trainingSet)[randIndex])
    #得到训练集矩阵
    trainMat = []; trainClasses = []
    for docIndex in trainingSet:
        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))
        trainClasses.append(classList[docIndex])
```
##### &emsp;&emsp;&emsp;3.构建朴素贝叶斯训练函数：通过计算每个词在词库中出现的概率来计算属性条件概率
```python
def trainNB0(trainMatrix,trainCategory):
    # number of training docs
    numTrainDocs = len(trainMatrix)
    # number of vocab in training docs
    numWords = len(trainMatrix[0])

    # p(c = 1)
    pAusive = sum(trainCategory)/float(numTrainDocs)
    # p(X|c) vector
    p0Num = np.ones(numWords) # n X 1
    p1Num = np.ones(numWords)
    #初始化概率
    p0Denom = 2.0
    p1Denom = 2.0
    #对每篇训练文档
    #   对每个类别：
    #       词条出现在文档-->增加该词条的计数
    #       增加所有词条的计数
    #   对每个类别：
    #       对每个词条：
    #           该词条数除以总词条数得到条件概率
    for i in range(numTrainDocs):
        if trainCategory[i] ==1:
            #出现词计数 
            p1Num += trainMatrix[i] 
            #计算该类别词总个数       
            p1Denom += sum(trainMatrix[i]) 
        else:
            p0Num += trainMatrix[i]
            p0Denom += sum(trainMatrix[i])
    #对每个元素做除法
    # p(X|c) vector
    p1Vect = np.log(p1Num / p1Denom)
    p0Vect = np.log(p0Num / p0Denom)
    # 得到P(X|C=0) P(X|C=1) P(C=1)
    return p0Vect,p1Vect,pAusive
```
##### &emsp;&emsp;&emsp;4.利用朴素贝叶斯公式计算的到预测分类
```python
def classifyNB(vec2Classify,p0Vect,p1Vect,pClass1):
    p1 = sum(vec2Classify * p1Vect) + np.log(pClass1)
    p0 = sum(vec2Classify * p0Vect) + np.log(1.0 - pClass1)
    if p1 > p0:
        return 1
    else :
        return 0
```
##### &emsp;&emsp;&emsp;5.训练并得到错误率
```python
    p0V, p1V, pSpam = trainNB0(np.array(trainMat), np.array(trainClasses))
    errorCount = 0
    for docIndex in testSet:        #classify the remaining items
        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])
        if classifyNB(np.array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:
            errorCount += 1
            print("classification error", docList[docIndex])
    print('the error rate is: ', float(errorCount)/len(testSet))
```
##### &emsp;&emsp;&emsp;6.运行得结果
![结果截图](task1/task1_res.jpg)